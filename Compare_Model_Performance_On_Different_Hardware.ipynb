{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I2zqtRygzF3",
        "outputId": "da25c2ac-5c5e-406f-883d-5ae4fe10665b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.241-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.0+cu126)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Collecting ultralytics-thop>=2.0.18 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n",
            "Downloading ultralytics-8.3.241-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.241 ultralytics-thop-2.0.18\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo benchmark model=yolo11n.pt data=\"coco8.yaml\" imgsz=640 half=false device=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRHQyZmxhUTt",
        "outputId": "5b2c3940-108a-46a7-f058-c1c87b143929"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 109.2MB/s 0.0s\n",
            "\n",
            "WARNING âš ï¸ Dataset 'coco8.yaml' images not found, missing path '/content/datasets/coco8/images/val'\n",
            "\u001b[KDownloading https://ultralytics.com/assets/coco8.zip to '/content/datasets/coco8.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 432.8KB 18.5MB/s 0.0s\n",
            "\u001b[KUnzipping /content/datasets/coco8.zip to /content/datasets/coco8...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 25/25 5.3Kfiles/s 0.0s\n",
            "Dataset download success âœ… (0.3s), saved to \u001b[1m/content/datasets\u001b[0m\n",
            "\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 30.1MB/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1470.9Â±545.5 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 122.5it/s 0.0s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco8/labels/val.cache\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.5it/s 1.1s\n",
            "                   all          4         17      0.574       0.85      0.815       0.61\n",
            "Speed: 0.9ms preprocess, 31.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m starting export with torch 2.9.0+cu126...\n",
            "\u001b[34m\u001b[1mTorchScript:\u001b[0m export success âœ… 1.6s, saved as 'yolo11n.torchscript' (10.5 MB)\n",
            "\n",
            "Export complete (1.7s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.torchscript imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.torchscript imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n.torchscript for TorchScript inference...\n",
            "Loading yolo11n.torchscript for TorchScript inference...\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2255.6Â±881.0 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 82.2Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 54.0it/s 0.1s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.5ms preprocess, 10.4ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnx>=1.12.0,<2.0.0', 'onnxslim>=0.1.71', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 14 packages in 222ms\n",
            "Prepared 6 packages in 6.24s\n",
            "Installed 6 packages in 278ms\n",
            " + colorama==0.4.6\n",
            " + coloredlogs==15.0.1\n",
            " + humanfriendly==10.0\n",
            " + onnx==1.20.0\n",
            " + onnxruntime-gpu==1.23.2\n",
            " + onnxslim==0.1.80\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 7.4s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 20...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 8.8s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\n",
            "Export complete (8.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.onnx imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.23.2 with CUDAExecutionProvider\n",
            "Loading yolo11n.onnx for ONNX Runtime inference...\n",
            "Using ONNX Runtime 1.23.2 with CUDAExecutionProvider\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2084.7Â±351.7 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 93.2Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 42.7it/s 0.1s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.3ms preprocess, 12.9ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
            "ERROR âŒ Benchmark failure for OpenVINO: inference not supported on GPU\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 20...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['tensorrt-cu12>7.0.0,!=10.1.0'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 5 packages in 43.61s\n",
            "Prepared 4 packages in 1m 09s\n",
            "Uninstalled 1 package in 5ms\n",
            "Installed 4 packages in 9ms\n",
            " - nvidia-cuda-runtime-cu12==12.6.77\n",
            " + nvidia-cuda-runtime-cu12==12.9.79\n",
            " + tensorrt-cu12==10.14.1.48.post1\n",
            " + tensorrt-cu12-bindings==10.14.1.48.post1\n",
            " + tensorrt-cu12-libs==10.14.1.48.post1\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 113.7s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.14.1.48.post1...\n",
            "[12/23/2025-00:10:21] [TRT] [I] [MemUsageChange] Init CUDA: CPU -2, GPU +0, now: CPU 1518, GPU 428 (MiB)\n",
            "[12/23/2025-00:10:21] [TRT] [I] ----------------------------------------------------------------\n",
            "[12/23/2025-00:10:21] [TRT] [I] Input filename:   yolo11n.onnx\n",
            "[12/23/2025-00:10:21] [TRT] [I] ONNX IR version:  0.0.9\n",
            "[12/23/2025-00:10:21] [TRT] [I] Opset version:    20\n",
            "[12/23/2025-00:10:21] [TRT] [I] Producer name:    pytorch\n",
            "[12/23/2025-00:10:21] [TRT] [I] Producer version: 2.9.0\n",
            "[12/23/2025-00:10:21] [TRT] [I] Domain:           \n",
            "[12/23/2025-00:10:21] [TRT] [I] Model version:    0\n",
            "[12/23/2025-00:10:21] [TRT] [I] Doc string:       \n",
            "[12/23/2025-00:10:21] [TRT] [I] ----------------------------------------------------------------\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 84, 8400) DataType.FLOAT\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolo11n.engine\n",
            "[12/23/2025-00:10:21] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[12/23/2025-00:10:22] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +102, GPU +0, now: CPU 1735, GPU 428 (MiB)\n",
            "[12/23/2025-00:10:22] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
            "[12/23/2025-00:10:22] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
            "[12/23/2025-00:11:04] [TRT] [I] Compiler backend is used during engine build.\n",
            "[12/23/2025-00:11:51] [TRT] [I] Detected 1 inputs and 1 output network tensors.\n",
            "[12/23/2025-00:11:52] [TRT] [I] Total Host Persistent Memory: 414080 bytes\n",
            "[12/23/2025-00:11:52] [TRT] [I] Total Device Persistent Memory: 1457152 bytes\n",
            "[12/23/2025-00:11:52] [TRT] [I] Max Scratch Memory: 2764800 bytes\n",
            "[12/23/2025-00:11:52] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 283 steps to complete.\n",
            "[12/23/2025-00:11:52] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 24.808ms to assign 10 blocks to 283 nodes requiring 19251712 bytes.\n",
            "[12/23/2025-00:11:52] [TRT] [I] Total Activation Memory: 19251200 bytes\n",
            "[12/23/2025-00:11:52] [TRT] [I] Total Weights Memory: 11628612 bytes\n",
            "[12/23/2025-00:11:52] [TRT] [I] Compiler backend is used during engine execution.\n",
            "[12/23/2025-00:11:52] [TRT] [I] Engine generation completed in 89.5217 seconds.\n",
            "[12/23/2025-00:11:52] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 261 MiB\n",
            "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success âœ… 209.4s, saved as 'yolo11n.engine' (12.4 MB)\n",
            "\n",
            "Export complete (209.5s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.engine imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.engine imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n.engine for TensorRT inference...\n",
            "[12/23/2025-00:11:52] [TRT] [I] Loaded engine size: 12 MiB\n",
            "[12/23/2025-00:11:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +20, now: CPU 0, GPU 32 (MiB)\n",
            "Loading yolo11n.engine for TensorRT inference...\n",
            "[12/23/2025-00:11:52] [TRT] [W] WARNING The logger passed into createInferRuntime differs from one already registered for an existing builder, runtime, or refitter. So the current new logger is ignored, and TensorRT will use the existing one which is returned by nvinfer1::getLogger() instead.\n",
            "[12/23/2025-00:11:52] [TRT] [I] Loaded engine size: 12 MiB\n",
            "[12/23/2025-00:11:52] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +1, GPU +20, now: CPU 1, GPU 64 (MiB)\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 893.6Â±416.8 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 72.3Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 54.5it/s 0.1s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.0ms preprocess, 4.3ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "ERROR âŒ Benchmark failure for CoreML: inference not supported on GPU\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766448715.105023    2578 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766448715.178881    2578 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766448715.737768    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766448715.737840    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766448715.737845    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766448715.737850    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0', 'onnx2tf>=1.26.3'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 12 packages in 1.52s\n",
            "Prepared 5 packages in 155ms\n",
            "Installed 5 packages in 7ms\n",
            " + ai-edge-litert==2.1.0\n",
            " + backports-strenum==1.3.1\n",
            " + onnx-graphsurgeon==0.5.8\n",
            " + onnx2tf==1.28.7\n",
            " + sng4onnx==1.0.4\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 1.8s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 20...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.1s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 32.8MB/s 0.0s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 46.0files/s 0.0s\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.7...\n",
            "I0000 00:00:1766448733.244666    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "I0000 00:00:1766448736.985492    2578 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "Saved artifact at 'yolo11n_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 84, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  16603332147152: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603332145616: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  16603332146384: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603299727888: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603332146960: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603299726928: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603332147344: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603299727312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299729040: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299728656: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299730960: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n",
            "  16603299731536: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n",
            "  16603299728272: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n",
            "  16603299728080: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603299729616: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299729232: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299731728: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n",
            "  16603299732304: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603299730576: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603299732688: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603299730384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603299732880: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603299732496: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603299733840: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299733072: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299734224: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  16603299735184: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603299731152: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603299731920: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299733264: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299733648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299735376: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
            "  16603299732112: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603299735760: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603299734416: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603299735568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603299735952: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603299736144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603299736720: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299736528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299738640: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603299738832: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299738064: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603299739024: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299739216: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603299739408: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299738256: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603299739792: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299737680: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603299734608: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603299739984: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299736336: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603299740560: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603299739600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603299736912: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299737104: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603299740752: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603299740944: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603299741136: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603299740176: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603299740368: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603299741520: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603299741328: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057029776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057029584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057031696: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603057031888: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057031120: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603057032080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057032272: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603057032464: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057031312: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603057032848: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057030736: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603057029392: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603057033040: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057029200: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057033616: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603057032656: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057029968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057030160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057033808: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603057034000: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057033232: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  16603057034192: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057034384: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  16603057033424: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057034768: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603057035344: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057035152: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603057035728: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057034960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  16603057035920: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057036496: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603057041104: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057039760: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603057039952: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057040912: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  16603057040720: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057040144: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603057039568: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603057040336: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  16603057038800: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057040528: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057041488: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057042832: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603057043024: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603057034576: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  16603057041296: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057041872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057038032: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057043600: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603057042256: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603057042448: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  16603057042640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603057044368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057044176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057043984: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  16603057045328: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603057043792: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603057044944: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603057044560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057044752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603057045136: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  16603055850896: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055850704: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603055849936: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055850512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055853008: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603055852432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603055855696: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055855312: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055856464: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603055853584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603055857616: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  16603055857424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055854352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055855504: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055857040: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603055858960: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603055859344: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603055857232: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603055858384: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603055859728: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603055858768: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603055859920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055860688: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055862992: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603055860880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055863760: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055862416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055864720: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055864336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055865296: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055862608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055864912: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055861072: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603055865488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055862032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055865104: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603055865680: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603055861264: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055861456: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603055851664: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  16603055851856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055864144: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603055864528: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603055852624: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
            "  16603055851088: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052392720: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  16603055855888: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  16603052393296: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603055856848: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603052394064: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
            "  16603055854544: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  16603055854160: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603052393104: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055858192: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055854928: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052393680: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603052392528: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  16603055860304: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603055855120: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603055851472: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603052394832: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052392912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055860496: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055857808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055851280: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055858000: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603055856656: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052395216: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603052393488: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055863568: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603055858576: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055852240: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603052394448: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052393872: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055863184: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055859152: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055852048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603052395408: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603052394256: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055863952: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603055860112: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603055853776: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603055853200: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603052394640: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603052395600: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055859536: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055863376: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603055853968: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603055856272: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603052397136: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  16603052397712: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603052397904: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603052398480: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603052396560: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603052398864: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  16603052397328: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "I0000 00:00:1766448746.736497    2578 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1766448746.736650    2578 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1766448746.737535    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W0000 00:00:1766448747.551380    2578 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1766448747.551415    2578 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1766448748.288588    2578 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1766448748.288737    2578 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1766448748.289678    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W0000 00:00:1766448748.997489    2578 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1766448748.997526    2578 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 36.8s, saved as 'yolo11n_saved_model' (25.7 MB)\n",
            "\n",
            "Export complete (36.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n_saved_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n_saved_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n_saved_model for TensorFlow SavedModel inference...\n",
            "Loading yolo11n_saved_model for TensorFlow SavedModel inference...\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1933.4Â±351.1 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 88.8Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 6.8it/s 0.6s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 2.1ms preprocess, 137.0ms inference, 0.0ms loss, 2.3ms postprocess per image\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 20...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.0s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.7...\n",
            "Saved artifact at 'yolo11n_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 84, 8400), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  16603035872784: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603035872592: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  16603035873360: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603035873744: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603035873552: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603035871056: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603035874512: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603035874128: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603035874896: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035874704: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035876624: TensorSpec(shape=(3, 3, 16, 8), dtype=tf.float32, name=None)\n",
            "  16603035876816: TensorSpec(shape=(8,), dtype=tf.float32, name=None)\n",
            "  16603035874320: TensorSpec(shape=(3, 3, 8, 16), dtype=tf.float32, name=None)\n",
            "  16603035873936: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603035871632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035875088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035877008: TensorSpec(shape=(1, 1, 48, 64), dtype=tf.float32, name=None)\n",
            "  16603035875664: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035877200: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603035876048: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035876240: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022016592: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022016976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022017552: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022017360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022019472: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  16603022019664: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603022017168: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603022016784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022017744: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022017936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022019856: TensorSpec(shape=(1, 1, 96, 128), dtype=tf.float32, name=None)\n",
            "  16603022018512: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022020240: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603022018896: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603022020048: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022020432: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603022020624: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022021200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022021008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022023120: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603022023312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022022544: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603022023504: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022023696: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603022023888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022022736: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603022024272: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022022160: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  16603022019088: TensorSpec(shape=(1, 1, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603022024464: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022020816: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603022025040: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022024080: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022021392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022021584: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022025232: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603022025424: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022025616: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603022024656: TensorSpec(shape=(3, 3, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603022024848: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603022026000: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603022026192: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603022026768: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022026576: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022028688: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603022028880: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022028112: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022029072: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022029264: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022029456: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022028304: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022029840: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022027728: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603022025808: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603022030032: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022026384: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603022030608: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603022029648: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022026960: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022027152: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603022030800: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603022030992: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603022030224: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  16603022031184: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022031376: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  16603022031760: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603022031568: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603022031952: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603022032336: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603022030416: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603018428496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  16603022032528: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603022032144: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603022032720: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603018429840: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  16603018428688: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603018429456: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  16603018430416: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603018429264: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  16603018430032: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603018430608: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  16603018429072: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603018430992: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018429648: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018432912: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603018433104: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603018430800: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  16603018430224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018431184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018431376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018433296: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603018431952: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603018432528: TensorSpec(shape=(1, 1, 256, 64), dtype=tf.float32, name=None)\n",
            "  16603018432336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018434064: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018433872: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018435984: TensorSpec(shape=(3, 3, 32, 16), dtype=tf.float32, name=None)\n",
            "  16603018436176: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  16603018433680: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  16603018433488: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16603018434256: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018434448: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018436368: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  16603018435024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018436752: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603018435408: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603018436560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018438672: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603018438096: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603018441360: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018440976: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018442128: TensorSpec(shape=(3, 3, 64, 32), dtype=tf.float32, name=None)\n",
            "  16603018439248: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  16614142393232: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  16614142393424: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018440016: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018441168: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035869904: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  16603035869136: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603035868752: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  16603035870672: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603035870480: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603035868368: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603035871248: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603035868176: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035867408: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035865104: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603035867216: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035864336: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035865680: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035863376: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035863760: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035862416: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035865488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035863184: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035867024: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603035862608: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035866064: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035862992: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  16603035862224: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603035866832: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603035866640: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  16603018437328: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  16603018437520: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035861648: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  16603035861840: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603018438288: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
            "  16603018435600: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035862032: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  16603035869520: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  16603035861456: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  16603035871440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  16603035862800: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
            "  16603035872976: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  16603018439824: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603035861072: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035872400: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603018440592: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603034109136: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603035863952: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  16603035867792: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  16603035870288: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  16603018437136: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603034123536: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035863568: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035867600: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035870096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018436944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018443664: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603018442320: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603034123152: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603035861264: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035864528: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603035869328: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603018437904: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603034123920: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035870864: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035864912: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035868944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603018437712: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603034122960: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603034124112: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603035864144: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603035867984: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16613402365584: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  16603018438864: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  16603034123728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603034122768: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603035868560: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035864720: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603018439632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  16603035869712: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  16603034121808: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  16603034122576: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603034122192: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603034121616: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603034123344: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  16603034119696: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  16603034120656: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "I0000 00:00:1766448763.692018    2578 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1766448763.692198    2578 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1766448763.693069    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W0000 00:00:1766448764.494249    2578 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1766448764.494282    2578 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "I0000 00:00:1766448765.173994    2578 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1766448765.174143    2578 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1766448765.175012    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "W0000 00:00:1766448765.888988    2578 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
            "W0000 00:00:1766448765.889029    2578 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 15.2s, saved as 'yolo11n_saved_model' (25.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "I0000 00:00:1766448767.214684    2578 devices.cc:67] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
            "I0000 00:00:1766448767.214849    2578 single_machine.cc:374] Starting new session\n",
            "I0000 00:00:1766448767.215708    2578 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13652 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "\u001b[34m\u001b[1mTensorFlow GraphDef:\u001b[0m export success âœ… 1.2s, saved as 'yolo11n.pb' (10.3 MB)\n",
            "\n",
            "Export complete (16.4s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.pb imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.pb imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n.pb for TensorFlow GraphDef inference...\n",
            "Loading yolo11n.pb for TensorFlow GraphDef inference...\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1193.7Â±536.2 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 75.6Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.2it/s 0.8s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.2ms preprocess, 186.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "ERROR âŒ Benchmark failure for TensorFlow Lite: inference not supported on GPU\n",
            "ERROR âŒ Benchmark failure for TensorFlow Edge TPU: inference not supported on GPU\n",
            "ERROR âŒ Benchmark failure for TensorFlow.js: inference not supported on GPU\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['paddlepaddle-gpu', 'x2paddle'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 18 packages in 160ms\n",
            "Prepared 4 packages in 1m 15s\n",
            "Uninstalled 1 package in 1ms\n",
            "Installed 4 packages in 58ms\n",
            " + astor==0.8.1\n",
            " - opt-einsum==3.4.0\n",
            " + opt-einsum==3.3.0\n",
            " + paddlepaddle-gpu==2.6.2\n",
            " + x2paddle==1.6.0\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 75.7s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mPaddlePaddle:\u001b[0m starting export with X2Paddle 1.6.0...\n",
            "INFO:x2paddle.convert:Now translating model from PyTorch to Paddle.\n",
            "INFO:x2paddle.convert:Model optimizing ...\n",
            "INFO:x2paddle.convert:Model optimized!\n",
            "Exporting inference model from python code ('/content/yolo11n_paddle_model/x2paddle_code.py')... \n",
            "\n",
            "W1223 00:14:12.418604  2578 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 7.5, Driver API Version: 12.4, Runtime API Version: 11.8\n",
            "W1223 00:14:12.447031  2578 gpu_resources.cc:164] device: 0, cuDNN Version: 9.2.\n",
            "I1223 00:14:14.119434  2578 program_interpreter.cc:212] New Executor is Running.\n",
            "INFO:x2paddle.convert:Successfully exported Paddle static graph model!\n",
            "INFO:x2paddle.convert:================================================\n",
            "INFO:x2paddle.convert:\n",
            "INFO:x2paddle.convert:Model Converted! Fill this survey to help X2Paddle better, https://iwenjuan.baidu.com/?code=npyd51 \n",
            "INFO:x2paddle.convert:\n",
            "INFO:x2paddle.convert:================================================\n",
            "\u001b[34m\u001b[1mPaddlePaddle:\u001b[0m export success âœ… 83.5s, saved as 'yolo11n_paddle_model/' (20.4 MB)\n",
            "\n",
            "Export complete (83.5s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n_paddle_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n_paddle_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n_paddle_model for PaddlePaddle inference...\n",
            "ERROR âŒ Benchmark failure for PaddlePaddle: Paddle model not found in yolo11n_paddle_model. Both .json and .pdiparams files are required.\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.20.0 opset 20...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.80...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.1s, saved as 'yolo11n.onnx' (10.2 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['MNN>=2.9.6'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 2 packages in 161ms\n",
            "Prepared 1 package in 1.38s\n",
            "Installed 1 package in 3ms\n",
            " + mnn==3.2.5\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 1.7s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "The device supports: i8sdot:0, fp16:0, i8mm: 0, sve2: 0, sme2: 0\n",
            "The device supports: i8sdot:0, fp16:0, i8mm: 0, sve2: 0, sme2: 0\n",
            "try 'pip install -U aliyun-log-python-sdk'\n",
            "Collecting aliyun-log-python-sdk\n",
            "  Downloading aliyun_log_python_sdk-0.9.37.tar.gz (152 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m152.5/152.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from aliyun-log-python-sdk) (1.17.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from aliyun-log-python-sdk) (2.32.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from aliyun-log-python-sdk) (2.9.0.post0)\n",
            "Collecting elasticsearch (from aliyun-log-python-sdk)\n",
            "  Downloading elasticsearch-9.2.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting jmespath (from aliyun-log-python-sdk)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting dateparser (from aliyun-log-python-sdk)\n",
            "  Downloading dateparser-1.2.2-py3-none-any.whl.metadata (29 kB)\n",
            "Requirement already satisfied: protobuf<6.0.0,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from aliyun-log-python-sdk) (5.29.5)\n",
            "Collecting lz4 (from aliyun-log-python-sdk)\n",
            "  Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: pytz>=2024.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->aliyun-log-python-sdk) (2025.2)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from dateparser->aliyun-log-python-sdk) (2025.11.3)\n",
            "Requirement already satisfied: tzlocal>=0.2 in /usr/local/lib/python3.12/dist-packages (from dateparser->aliyun-log-python-sdk) (5.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from elasticsearch->aliyun-log-python-sdk) (4.12.0)\n",
            "Collecting elastic-transport<10,>=9.2.0 (from elasticsearch->aliyun-log-python-sdk)\n",
            "  Downloading elastic_transport-9.2.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from elasticsearch->aliyun-log-python-sdk) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from elasticsearch->aliyun-log-python-sdk) (4.15.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->aliyun-log-python-sdk) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->aliyun-log-python-sdk) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->aliyun-log-python-sdk) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->aliyun-log-python-sdk) (2025.11.12)\n",
            "Downloading dateparser-1.2.2-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m315.5/315.5 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elasticsearch-9.2.0-py3-none-any.whl (960 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m960.5/960.5 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lz4-4.4.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading elastic_transport-9.2.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: aliyun-log-python-sdk\n",
            "  Building wheel for aliyun-log-python-sdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-log-python-sdk: filename=aliyun_log_python_sdk-0.9.37-py3-none-any.whl size=200275 sha256=3296cca82f1d13097ff687aa720232c187ae4745037b38d275a1d769539abf19\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/90/c3/a31cf1d6c3abdb309f27408609103b8045ac0eb79d45bed092\n",
            "Successfully built aliyun-log-python-sdk\n",
            "Installing collected packages: lz4, jmespath, elastic-transport, elasticsearch, dateparser, aliyun-log-python-sdk\n",
            "Successfully installed aliyun-log-python-sdk-0.9.37 dateparser-1.2.2 elastic-transport-9.2.0 elasticsearch-9.2.0 jmespath-1.0.1 lz4-4.4.5\n",
            "\n",
            "\u001b[34m\u001b[1mMNN:\u001b[0m starting export with MNN 3.2.5...\n",
            "Start to Convert Other Model Format To MNN Model..., target version: 3.2\n",
            "[00:14:25] :46: ONNX Model ir version: 9\n",
            "[00:14:25] :47: ONNX Model opset version: 20\n",
            "[00:14:25] :149: Check it out ==> /model.11/Resize_output_0 has empty input, the index is 1\n",
            "[00:14:25] :149: Check it out ==> /model.14/Resize_output_0 has empty input, the index is 1\n",
            "Start to Optimize the MNN Net...\n",
            "inputTensors : [ images, ]\n",
            "outputTensors: [ output0, ]\n",
            "Converted Success!\n",
            "\u001b[34m\u001b[1mMNN:\u001b[0m export success âœ… 11.8s, saved as 'yolo11n.mnn' (10.1 MB)\n",
            "\n",
            "Export complete (11.9s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n.mnn imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n.mnn imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n.mnn for MNN inference...\n",
            "MNN use low precision\n",
            "Loading yolo11n.mnn for MNN inference...\n",
            "MNN use low precision\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1740.7Â±613.1 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 80.7Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 7.9it/s 0.5s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.6ms preprocess, 117.7ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolo11n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (5.4 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['ncnn'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 1 package in 121ms\n",
            "Prepared 1 package in 174ms\n",
            "Installed 1 package in 1ms\n",
            " + ncnn==1.0.20250916\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 0.4s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['pnnx'] not found, attempting AutoUpdate...\n",
            "Using Python 3.12.12 environment at: /usr\n",
            "Resolved 27 packages in 750ms\n",
            "Prepared 2 packages in 1.62s\n",
            "Uninstalled 1 package in 5ms\n",
            "Installed 2 packages in 3ms\n",
            " - nvidia-cuda-runtime-cu12==12.9.79\n",
            " + nvidia-cuda-runtime-cu12==12.6.77\n",
            " + pnnx==20251119\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 2.5s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mNCNN:\u001b[0m starting export with NCNN 1.0.20250916 and PNNX 20251119...\n",
            "pnnxparam = yolo11n_ncnn_model/model.pnnx.param\n",
            "pnnxbin = yolo11n_ncnn_model/model.pnnx.bin\n",
            "pnnxpy = yolo11n_ncnn_model/model_pnnx.py\n",
            "pnnxonnx = yolo11n_ncnn_model/model.pnnx.onnx\n",
            "ncnnparam = yolo11n_ncnn_model/model.ncnn.param\n",
            "ncnnbin = yolo11n_ncnn_model/model.ncnn.bin\n",
            "ncnnpy = yolo11n_ncnn_model/model_ncnn.py\n",
            "fp16 = 0\n",
            "optlevel = 2\n",
            "device = cuda\n",
            "inputshape = [1,3,640,640]f32\n",
            "inputshape2 = \n",
            "customop = \n",
            "moduleop = \n",
            "############# pass_level0\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "inline module = ultralytics.nn.modules.block.Attention\n",
            "inline module = ultralytics.nn.modules.block.Bottleneck\n",
            "inline module = ultralytics.nn.modules.block.C2PSA\n",
            "inline module = ultralytics.nn.modules.block.C3k\n",
            "inline module = ultralytics.nn.modules.block.C3k2\n",
            "inline module = ultralytics.nn.modules.block.DFL\n",
            "inline module = ultralytics.nn.modules.block.PSABlock\n",
            "inline module = ultralytics.nn.modules.block.SPPF\n",
            "inline module = ultralytics.nn.modules.conv.Concat\n",
            "inline module = ultralytics.nn.modules.conv.Conv\n",
            "inline module = ultralytics.nn.modules.conv.DWConv\n",
            "inline module = ultralytics.nn.modules.head.Detect\n",
            "inline module = torch.nn.modules.linear.Identity\n",
            "inline module = ultralytics.nn.modules.block.Attention\n",
            "inline module = ultralytics.nn.modules.block.Bottleneck\n",
            "inline module = ultralytics.nn.modules.block.C2PSA\n",
            "inline module = ultralytics.nn.modules.block.C3k\n",
            "inline module = ultralytics.nn.modules.block.C3k2\n",
            "inline module = ultralytics.nn.modules.block.DFL\n",
            "inline module = ultralytics.nn.modules.block.PSABlock\n",
            "inline module = ultralytics.nn.modules.block.SPPF\n",
            "inline module = ultralytics.nn.modules.conv.Concat\n",
            "inline module = ultralytics.nn.modules.conv.Conv\n",
            "inline module = ultralytics.nn.modules.conv.DWConv\n",
            "inline module = ultralytics.nn.modules.head.Detect\n",
            "\n",
            "----------------\n",
            "\n",
            "############# pass_level1\n",
            "############# pass_level2\n",
            "############# pass_level3\n",
            "############# pass_level4\n",
            "############# pass_level5\n",
            "############# pass_ncnn\n",
            "\u001b[34m\u001b[1mNCNN:\u001b[0m export success âœ… 7.0s, saved as 'yolo11n_ncnn_model' (10.2 MB)\n",
            "\n",
            "Export complete (7.1s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolo11n_ncnn_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolo11n_ncnn_model imgsz=640 data=/usr/src/ultralytics/ultralytics/cfg/datasets/coco.yaml  \n",
            "Visualize:       https://netron.app\n",
            "Loading yolo11n_ncnn_model for NCNN inference...\n",
            "Loading yolo11n_ncnn_model for NCNN inference...\n",
            "Setting batch=1 input of shape (1, 3, 640, 640)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1889.8Â±202.2 MB/s, size: 54.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 92.7Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 5.6it/s 0.7s\n",
            "                   all          4         17      0.846      0.637       0.85      0.608\n",
            "Speed: 1.8ms preprocess, 169.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "ERROR âŒ Benchmark failure for IMX: IMX only supported for YOLOv8n and YOLO11n\n",
            "ERROR âŒ Benchmark failure for RKNN: inference not supported on GPU\n",
            "ERROR âŒ Benchmark failure for ExecuTorch: inference not supported on GPU\n",
            "ERROR âŒ Benchmark failure for Axelera: inference not supported on GPU\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 47.9/112.6 GB disk)\n",
            "\n",
            "Benchmarks complete for yolo11n.pt on coco8.yaml at imgsz=640 (394.31s)\n",
            "Benchmarks legend:  - âœ… Success  - â Export passed but validation failed  - âŒï¸ Export failed\n",
            "+-----------------------------------------------------------------------------------------------------------+\n",
            "|      Format                  Statusâ”   Size (MB)   metrics/mAP50-95(B)   Inference time (ms/im)   FPS    |\n",
            "+===========================================================================================================+\n",
            "| 1    PyTorch                 âœ…         5.4         0.61                  31.88                    31.37  |\n",
            "| 2    TorchScript             âœ…         10.5        0.6082                10.45                    95.69  |\n",
            "| 3    ONNX                    âœ…         10.2        0.6082                12.87                    77.68  |\n",
            "| 4    OpenVINO                âŒ         0.0         -                     -                        -      |\n",
            "| 5    TensorRT                âœ…         12.4        0.6082                4.27                     234.22 |\n",
            "| 6    CoreML                  âŒ         0.0         -                     -                        -      |\n",
            "| 7    TensorFlow SavedModel   âœ…         25.7        0.6082                136.98                   7.3    |\n",
            "| 8    TensorFlow GraphDef     âœ…         10.3        0.6082                186.32                   5.37   |\n",
            "| 9    TensorFlow Lite         âŒ         0.0         -                     -                        -      |\n",
            "| 10   TensorFlow Edge TPU     âŒ         0.0         -                     -                        -      |\n",
            "| 11   TensorFlow.js           âŒ         0.0         -                     -                        -      |\n",
            "| 12   PaddlePaddle            â         20.4        -                     -                        -      |\n",
            "| 13   MNN                     âœ…         10.1        0.6082                117.72                   8.49   |\n",
            "| 14   NCNN                    âœ…         10.2        0.6082                169.75                   5.89   |\n",
            "| 15   IMX                     âŒ         0.0         -                     -                        -      |\n",
            "| 16   RKNN                    âŒ         0.0         -                     -                        -      |\n",
            "| 17   ExecuTorch              âŒ         0.0         -                     -                        -      |\n",
            "| 18   Axelera                 âŒ         0.0         -                     -                        -      |\n",
            "+-----------------------------------------------------------------------------------------------------------+\n",
            "\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/benchmark\n"
          ]
        }
      ]
    }
  ]
}